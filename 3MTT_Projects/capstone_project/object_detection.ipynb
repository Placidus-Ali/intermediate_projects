{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a49acab4-ce3f-4ecc-86fe-c0ba7603f2e1",
   "metadata": {},
   "source": [
    "### Real-Time Object Detection System\n",
    "\n",
    "This project uses the Pascal VOC dataset to develop a model that detects objects in live video feeds. You’ll begin by preparing a subset of the COCO dataset with classes relevant to your goals, such as \"person, car, bicycle, dog, cat or bus\" and perform data augmentation for robust training. With YOLOv5, a popular model for real-time applications, you’ll load pretrained weights and fine-tune them using your filtered dataset, aiming for accuracy and speed. \n",
    "\n",
    "For inference, you’ll integrate OpenCV to process video from a webcam or video file, running object detection in real time. The model draws bounding boxes around detected objects and labels them on the video feed, demonstrating strong applicability in real-time scenarios. \n",
    "\n",
    "Finally, you’ll deploy the solution using Streamlit, where users can upload video files or use their webcams to view real-time detections directly from a web interface. Streamlit’s simple deployment pipeline allows easy sharing of your project for remote access and feedback.\n",
    "\n",
    "With your background in data science and machine learning, this project leverages skills in model training, data preprocessing, and deployment, essential for your data science portfolio. It’s an excellent addition to your projects as it demonstrates practical applications of machine learning for real-time use cases—aligning with your goal to attract employers and stand out in the field."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ada01e3-b181-4d32-a07a-ad3f2dc8eec9",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb0e381e-57e2-4cdc-9705-1735f8676867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\anaconda\\lib\\site-packages (0.20.1)\n",
      "Requirement already satisfied: numpy in c:\\anaconda\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: torch==2.5.1 in c:\\anaconda\\lib\\site-packages (from torchvision) (2.5.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\anaconda\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: filelock in c:\\anaconda\\lib\\site-packages (from torch==2.5.1->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\anaconda\\lib\\site-packages (from torch==2.5.1->torchvision) (4.11.0)\n",
      "Requirement already satisfied: setuptools in c:\\anaconda\\lib\\site-packages (from torch==2.5.1->torchvision) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\anaconda\\lib\\site-packages (from torch==2.5.1->torchvision) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\anaconda\\lib\\site-packages (from torch==2.5.1->torchvision) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\anaconda\\lib\\site-packages (from torch==2.5.1->torchvision) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\anaconda\\lib\\site-packages (from torch==2.5.1->torchvision) (2024.6.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\anaconda\\lib\\site-packages (from sympy==1.13.1->torch==2.5.1->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\anaconda\\lib\\site-packages (from jinja2->torch==2.5.1->torchvision) (2.1.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Anaconda\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Anaconda\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Anaconda\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b16a33-7e7a-4f7e-8b8e-c2c54ad445ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "import numpy as np\n",
    "import streamlit as st\n",
    "from PIL import Image\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "802f6087-35dc-4783-9065-e78466bf08e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torchvision' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(torchvision\u001b[38;5;241m.\u001b[39m__version__)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torchvision' is not defined"
     ]
    }
   ],
   "source": [
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017a61bd-cace-4594-99df-e5b437bfcc9e",
   "metadata": {},
   "source": [
    "torch: A core library for deep learning.\n",
    "torchvision: Contains pre-trained models and datasets, especially for computer vision.\n",
    "fasterrcnn_resnet50_fpn: Pre-trained Faster R-CNN model with a ResNet-50 backbone.\n",
    "cv2: OpenCV for handling real-time image streams.\n",
    "numpy: To handle arrays.\n",
    "streamlit: Used for building the web interface.\n",
    "PIL.Image: To process image formats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce97970-b844-4396-8983-a6b2feceb6d7",
   "metadata": {},
   "source": [
    "Load the Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b9fb3e4-0640-4419-b035-d352eca0b655",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load Faster R-CNN pre-trained on Pascal VOC\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mdetection\u001b[38;5;241m.\u001b[39mfasterrcnn_resnet50_fpn(pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#model = models.detection.fasterrcnn_resnet50_fpn(weights=models.detection.FasterRCNN_ResNet50_FPN_Weights.DEFAULT)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39meval()  \u001b[38;5;66;03m# Set the model to evaluation mode\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "# Load Faster R-CNN pre-trained on Pascal VOC\n",
    "model = models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "#model = models.detection.fasterrcnn_resnet50_fpn(weights=models.detection.FasterRCNN_ResNet50_FPN_Weights.DEFAULT)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Check for CUDA support to run on GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb1fe39-b9ad-4cbb-a39b-8240190bf305",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
